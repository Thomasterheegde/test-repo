{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75acf8e0",
   "metadata": {},
   "source": [
    "# AML computer workshop. Introduction to Neural Networks\n",
    "\n",
    "In this last installment of your AML workshops we will look at implementing neural networks. You will remember from the lecture that broadly speaking, a neural network consists of an input and an output layer of neurons which are connected with a number of hidden layers.\n",
    "\n",
    "The maybe easiest way to build an ANN in Python is through Keras.\n",
    "\n",
    "Keras is a Python interface that focuses on neural networks and especially shines for deep learning implementations. It was built on top of [TensorFlow](https://tensorflow.org/), which in turn was originally written for internal uses at Google but has since become a large open source software library for machine learning. Keras is an interface to make it easier to use, which makes it a very popular choice for ANN implementations with plenty of customization options. You'll remember from the lecture how many choices can be made regarding the structure and the tuning of a neural network. Keras will help us with that. Have a brief look at their extensive documentation [here](https://keras.io/about/). These easy to use libraries are arguably one of the reasons why neural networks have been so popular.\n",
    "\n",
    "On the Keras website there's tutorials for both simple implementations like the ones we're doing in class here, but also more advanced options such as parallel processing and recurrent ANNs which are used for example in Natural Language Processing (NLP) for those of you interested in diving deeper after the course.\n",
    "\n",
    "This script will construct a simple neural network for our churn data. Remember that churn reflects whether a customer will stop buying a product from a company."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "55a80a37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.16.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (589.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m589.8/589.8 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: wrapt>=1.11.0 in /opt/conda/lib/python3.9/site-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.9/site-packages (from tensorflow) (65.4.1)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.36.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m111.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting astunparse>=1.6.0\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1\n",
      "  Downloading gast-0.5.4-py3-none-any.whl (19 kB)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.9/site-packages (from tensorflow) (2.28.1)\n",
      "Collecting h5py>=3.10.0\n",
      "  Downloading h5py-3.10.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m106.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting keras>=3.0.0\n",
      "  Downloading keras-3.0.5-py3-none-any.whl (1.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m79.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy<2.0.0,>=1.23.5 in /opt/conda/lib/python3.9/site-packages (from tensorflow) (1.23.5)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.9/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /opt/conda/lib/python3.9/site-packages (from tensorflow) (3.20.3)\n",
      "Collecting termcolor>=1.1.0\n",
      "  Downloading termcolor-2.4.0-py3-none-any.whl (7.7 kB)\n",
      "Collecting ml-dtypes~=0.3.1\n",
      "  Downloading ml_dtypes-0.3.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m106.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting libclang>=13.0.0\n",
      "  Downloading libclang-16.0.6-py2.py3-none-manylinux2010_x86_64.whl (22.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22.9/22.9 MB\u001b[0m \u001b[31m80.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: absl-py>=1.0.0 in /opt/conda/lib/python3.9/site-packages (from tensorflow) (1.4.0)\n",
      "Collecting google-pasta>=0.1.1\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.9/site-packages (from tensorflow) (1.16.0)\n",
      "Collecting flatbuffers>=23.5.26\n",
      "  Downloading flatbuffers-24.3.7-py2.py3-none-any.whl (26 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.9/site-packages (from tensorflow) (4.7.1)\n",
      "Collecting tensorboard<2.17,>=2.16\n",
      "  Downloading tensorboard-2.16.2-py3-none-any.whl (5.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m111.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.9/site-packages (from tensorflow) (1.47.5)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.9/site-packages (from tensorflow) (23.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.9/site-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
      "Collecting namex\n",
      "  Downloading namex-0.0.7-py3-none-any.whl (5.8 kB)\n",
      "Collecting dm-tree\n",
      "  Downloading dm_tree-0.1.8-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (153 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.0/153.0 kB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: rich in /opt/conda/lib/python3.9/site-packages (from keras>=3.0.0->tensorflow) (13.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorflow) (2023.7.22)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorflow) (1.26.16)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorflow) (2.1.1)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m113.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.9/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (3.4.4)\n",
      "Collecting grpcio<2.0,>=1.24.3\n",
      "  Downloading grpcio-1.62.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m111.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting werkzeug>=1.0.1\n",
      "  Downloading werkzeug-3.0.1-py3-none-any.whl (226 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m226.7/226.7 kB\u001b[0m \u001b[31m30.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: importlib-metadata>=4.4 in /opt/conda/lib/python3.9/site-packages (from markdown>=2.6.8->tensorboard<2.17,>=2.16->tensorflow) (6.8.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.9/site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.9/site-packages (from rich->keras>=3.0.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.9/site-packages (from rich->keras>=3.0.0->tensorflow) (2.13.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.9/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.17,>=2.16->tensorflow) (3.9.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.9/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow) (0.1.2)\n",
      "Installing collected packages: namex, libclang, flatbuffers, dm-tree, werkzeug, termcolor, tensorflow-io-gcs-filesystem, tensorboard-data-server, ml-dtypes, h5py, grpcio, google-pasta, gast, astunparse, tensorboard, keras, tensorflow\n",
      "  Attempting uninstall: h5py\n",
      "    Found existing installation: h5py 3.6.0\n",
      "    Uninstalling h5py-3.6.0:\n",
      "      Successfully uninstalled h5py-3.6.0\n",
      "  Attempting uninstall: grpcio\n",
      "    Found existing installation: grpcio 1.47.5\n",
      "    Uninstalling grpcio-1.47.5:\n",
      "      Successfully uninstalled grpcio-1.47.5\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "momento 1.9.1 requires pyjwt<3.0.0,>=2.4.0, but you have pyjwt 1.7.1 which is incompatible.\n",
      "jina 3.20.1 requires grpcio<1.48.1,>=1.46.0, but you have grpcio 1.62.1 which is incompatible.\n",
      "jina 3.20.1 requires prometheus-client>=0.12.0, but you have prometheus-client 0.7.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed astunparse-1.6.3 dm-tree-0.1.8 flatbuffers-24.3.7 gast-0.5.4 google-pasta-0.2.0 grpcio-1.62.1 h5py-3.10.0 keras-3.0.5 libclang-16.0.6 ml-dtypes-0.3.2 namex-0.0.7 tensorboard-2.16.2 tensorboard-data-server-0.7.2 tensorflow-2.16.1 tensorflow-io-gcs-filesystem-0.36.0 termcolor-2.4.0 werkzeug-3.0.1\n",
      "Requirement already satisfied: keras in /opt/conda/lib/python3.9/site-packages (3.0.5)\n",
      "Requirement already satisfied: absl-py in /opt/conda/lib/python3.9/site-packages (from keras) (1.4.0)\n",
      "Requirement already satisfied: ml-dtypes in /opt/conda/lib/python3.9/site-packages (from keras) (0.3.2)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.9/site-packages (from keras) (1.23.5)\n",
      "Requirement already satisfied: dm-tree in /opt/conda/lib/python3.9/site-packages (from keras) (0.1.8)\n",
      "Requirement already satisfied: rich in /opt/conda/lib/python3.9/site-packages (from keras) (13.4.2)\n",
      "Requirement already satisfied: namex in /opt/conda/lib/python3.9/site-packages (from keras) (0.0.7)\n",
      "Requirement already satisfied: h5py in /opt/conda/lib/python3.9/site-packages (from keras) (3.10.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.9/site-packages (from rich->keras) (2.13.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.9/site-packages (from rich->keras) (3.0.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.9/site-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\r\n"
     ]
    }
   ],
   "source": [
    "# we'll need to install tensorflow and keras first, may take a few minutes\n",
    "\n",
    "!pip install tensorflow\n",
    "!pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c6d6cad9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customerID</th>\n",
       "      <th>gender</th>\n",
       "      <th>SeniorCitizen</th>\n",
       "      <th>Partner</th>\n",
       "      <th>Dependents</th>\n",
       "      <th>tenure</th>\n",
       "      <th>PhoneService</th>\n",
       "      <th>MultipleLines</th>\n",
       "      <th>InternetService</th>\n",
       "      <th>OnlineSecurity</th>\n",
       "      <th>...</th>\n",
       "      <th>DeviceProtection</th>\n",
       "      <th>TechSupport</th>\n",
       "      <th>StreamingTV</th>\n",
       "      <th>StreamingMovies</th>\n",
       "      <th>Contract</th>\n",
       "      <th>PaperlessBilling</th>\n",
       "      <th>PaymentMethod</th>\n",
       "      <th>MonthlyCharges</th>\n",
       "      <th>TotalCharges</th>\n",
       "      <th>Churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7590-VHVEG</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "      <td>No</td>\n",
       "      <td>No phone service</td>\n",
       "      <td>DSL</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Electronic check</td>\n",
       "      <td>29.85</td>\n",
       "      <td>29.85</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5575-GNVDE</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>34</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Yes</td>\n",
       "      <td>...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>One year</td>\n",
       "      <td>No</td>\n",
       "      <td>Mailed check</td>\n",
       "      <td>56.95</td>\n",
       "      <td>1889.50</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3668-QPYBK</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>2</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Yes</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Mailed check</td>\n",
       "      <td>53.85</td>\n",
       "      <td>108.15</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7795-CFOCW</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>45</td>\n",
       "      <td>No</td>\n",
       "      <td>No phone service</td>\n",
       "      <td>DSL</td>\n",
       "      <td>Yes</td>\n",
       "      <td>...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>One year</td>\n",
       "      <td>No</td>\n",
       "      <td>Bank transfer (automatic)</td>\n",
       "      <td>42.30</td>\n",
       "      <td>1840.75</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9237-HQITU</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>2</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Fiber optic</td>\n",
       "      <td>No</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Month-to-month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Electronic check</td>\n",
       "      <td>70.70</td>\n",
       "      <td>151.65</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   customerID  gender  SeniorCitizen Partner Dependents  tenure PhoneService  \\\n",
       "0  7590-VHVEG  Female              0     Yes         No       1           No   \n",
       "1  5575-GNVDE    Male              0      No         No      34          Yes   \n",
       "2  3668-QPYBK    Male              0      No         No       2          Yes   \n",
       "3  7795-CFOCW    Male              0      No         No      45           No   \n",
       "4  9237-HQITU  Female              0      No         No       2          Yes   \n",
       "\n",
       "      MultipleLines InternetService OnlineSecurity  ... DeviceProtection  \\\n",
       "0  No phone service             DSL             No  ...               No   \n",
       "1                No             DSL            Yes  ...              Yes   \n",
       "2                No             DSL            Yes  ...               No   \n",
       "3  No phone service             DSL            Yes  ...              Yes   \n",
       "4                No     Fiber optic             No  ...               No   \n",
       "\n",
       "  TechSupport StreamingTV StreamingMovies        Contract PaperlessBilling  \\\n",
       "0          No          No              No  Month-to-month              Yes   \n",
       "1          No          No              No        One year               No   \n",
       "2          No          No              No  Month-to-month              Yes   \n",
       "3         Yes          No              No        One year               No   \n",
       "4          No          No              No  Month-to-month              Yes   \n",
       "\n",
       "               PaymentMethod MonthlyCharges  TotalCharges  Churn  \n",
       "0           Electronic check          29.85         29.85     No  \n",
       "1               Mailed check          56.95       1889.50     No  \n",
       "2               Mailed check          53.85        108.15    Yes  \n",
       "3  Bank transfer (automatic)          42.30       1840.75     No  \n",
       "4           Electronic check          70.70        151.65    Yes  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "df = pd.read_csv('churn_ibm.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f3c9709",
   "metadata": {},
   "source": [
    "You already know our usual pre-processing steps by now, right?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "63de1422",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['Churn']\n",
    "X = df.drop(['Churn','customerID'],axis=1)\n",
    "\n",
    "for column in X.columns:\n",
    "    if X[column].dtype == object:\n",
    "        X = pd.concat([X,pd.get_dummies(X[column], prefix=column, drop_first=True)],axis=1).drop([column],axis=1)\n",
    "\n",
    "# Also for neural networks, it's best to scale the input variables. In contrast to decision trees with which, \n",
    "# we've analysed churn data in the past, ANNs are more sensitive to scaling issues.\n",
    "\n",
    "X = StandardScaler().fit_transform(X)\n",
    "y = pd.get_dummies(y, prefix='churn', drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fa19b264",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7539599c",
   "metadata": {},
   "source": [
    "# Section 1 - Demo: Building a two-layer feed-forward ANN\n",
    "\n",
    "We'll now build a neural network with two hidden layers using Keras. Have a look at the implementation example [here](https://keras.io/guides/sequential_model/).\n",
    "\n",
    "Notice when we can use the sequential model structure:\n",
    "- we have one input (our dataframe X)\n",
    "- we have one output (our data vector y)\n",
    "\n",
    "The code example shows you exactly how to build layers. If we want to build a model with three layers, the example suggests to write \n",
    "\n",
    "`model = keras.Sequential(\n",
    "    [\n",
    "        layers.Dense(2, activation=\"relu\", name=\"layer1\"),\n",
    "        layers.Dense(3, activation=\"relu\", name=\"layer2\"),\n",
    "        layers.Dense(4, name=\"layer3\"),\n",
    "    ]\n",
    ")`\n",
    "\n",
    "You define each layer in terms of the number of neurons it has (here: 2, 3 and 4), whether it is a dense layer (that is, each neuron in the previous layer is connected with each neuron in the next layer), and its activation function (here, relu). Pretty straightforward, right? \n",
    "\n",
    "The model can be built in one go, or you can use the add() function to add layers sequentially if you prefer. I will demonstrate the sequential way below.\n",
    "\n",
    "Note that you have to specify the shape of the input and output in your network. The example on the website does that a bit later. For our example, the shapes are 'X_train.shape[1]' and 'y_train.shape[1]'.\n",
    "\n",
    "**DEMO**\n",
    "\n",
    "For this example, I will demonstrate one way of building a two layer neural network for our churn data. You can use this example for the later tasks where you will have to build them yourself. If you would prefer to try it yourself instead of seeing my example, just skip the following cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3018a5bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input dimension:  30\n",
      "Output dimension:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/keras/src/layers/core/dense.py:85: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import layers\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "\n",
    "# I save input and output dim as variables, because that makes it easier to read the code\n",
    "input_dim = X_train.shape[1]\n",
    "output_dim = y_train.shape[1]\n",
    "print('Input dimension: ', input_dim)\n",
    "print('Output dimension: ', output_dim)\n",
    "\n",
    "# Create a model instance (Sequential, as we add each layer in order of appearance)\n",
    "model = Sequential()\n",
    "\n",
    "# Add the input layer and connect to 50 hidden neurons; this is your first hidden layer\n",
    "model.add(Dense(50,input_dim=input_dim))\n",
    "\n",
    "# Connect the neurons to the next 50 neurons; this is your second hidden layer\n",
    "model.add(Dense(50))\n",
    "\n",
    "# Connect the previous layer to the output layer; note we specify the output dimensions here (the dimension of our y)\n",
    "# and we use a sigmoid activation function here because that allows us the binary classification for our example\n",
    "model.add(Dense(output_dim, activation='sigmoid'))\n",
    "\n",
    "# Create the model with an optimizer, loss function, and evaluation metric.\n",
    "model.compile(optimizer='sgd',loss='binary_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "# We'll make some changes to these later, but for now we use Stochastic Gradient Descent (SGD) as an optimizer,\n",
    "# cross entropy as a cost function (remember that we are classifying, so cross entropy is appropriate here;\n",
    "# in a regression problem you would want to use for example MeanSquaredError) \n",
    "# and we want the network to be evaluated by its accuracy (other choices would be for example recall or \n",
    "# precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "40e9a7df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,550</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,550</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">51</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)             │         \u001b[38;5;34m1,550\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)             │         \u001b[38;5;34m2,550\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m51\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,151</span> (16.21 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,151\u001b[0m (16.21 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,151</span> (16.21 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m4,151\u001b[0m (16.21 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m154/154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.6768 - loss: 0.5968\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7f1340e9c370>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the above specified model with the training data\n",
    "model.summary()\n",
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f02ebb7b",
   "metadata": {},
   "source": [
    "The first part of the output shows the structure of your network: You'll see that we have two dense hidden layers with 50 nodes each, as well as one output layer of size 1 which has a sigmoid activation function to transform our output into probabilities.\n",
    "\n",
    "The total number of parameters that the model has to estimate is 4,151"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ebc976b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "[[0.08738211]\n",
      " [0.35881358]\n",
      " [0.35947344]\n",
      " ...\n",
      " [0.644313  ]\n",
      " [0.15029685]\n",
      " [0.33661768]]\n",
      "[[0]\n",
      " [0]\n",
      " [0]\n",
      " ...\n",
      " [1]\n",
      " [0]\n",
      " [0]]\n"
     ]
    }
   ],
   "source": [
    "# Test the model on our test data and obtain the results as predicted probabilities\n",
    "prediction_prob = model.predict(X_test)\n",
    "print(prediction_prob)\n",
    "\n",
    "# Also obtain the results as a class (here 0/1)\n",
    "classes=(prediction_prob > 0.5).astype(\"int32\")\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ed7dc6ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.804739336492891\n",
      "AUC: 0.8357398143203771\n"
     ]
    }
   ],
   "source": [
    "# Print our test accuracy and model AUC\n",
    "print('Accuracy:', accuracy_score(y_test,classes))\n",
    "print('AUC:',roc_auc_score(y_test,prediction_prob))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11eee597",
   "metadata": {},
   "source": [
    "The example above demonstrates how to build quite a complex model, but you can see how easy it is using Keras. Let's use this as a basis for the following exercise.\n",
    "\n",
    "# Section 2: Experimenting with Kernels and activation functions\n",
    "\n",
    "We've discussed in class that one of the advantages of neural networks lies in their ability to capture nonlinearity. We'll see that in action now as we try to classify a circular dataset.\n",
    "\n",
    "For that we will use kernels to capture nonlinearity. You've seen this work before in Support Vector Machines. I like to imagine kernels as a way to \"push\" data into other feature spaces to allow us to separate it. The Wikipedia article on kernel machines (https://en.wikipedia.org/wiki/Kernel_method) has a very intuitive picture for that process: if we have a scatterplot in two dimensions, we can \"push\" a kernel through that cloud of dots in order to separate them. Points of one class are suddenly pushed upwards into the new dimension as they are \"on top\" of the kernel shape. We are expanding the dimensions by one using the kernel and can now find a linear classifier that cuts through the kernel, separating the points \"on top\" from those \"on the bottom\". Different kernel shapes exist for different scenarios.\n",
    "\n",
    "### 2.1 Creating data\n",
    "\n",
    "Let's generate some data to see how this same trick is applied in neural networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ba3125f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          x         y  label\n",
      "0 -0.794197  0.033301      1\n",
      "1 -0.949054 -0.370677      0\n",
      "2  0.828743  0.410930      1\n",
      "3  0.779184  0.471178      0\n",
      "4 -0.339612 -0.745533      1\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import make_circles, make_checkerboard\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# scikit-learn offers a method to create a dataset perfect for this task by using make_circles\n",
    "X, y = make_circles(n_samples=1000, noise=0.05)\n",
    "\n",
    "df = pd.DataFrame(dict(x=X[:,0], y=X[:,1], label=y))\n",
    "colors = {0:'red', 1:'blue'}\n",
    "\n",
    "print(df.head())\n",
    "\n",
    "# Plotting the dataset\n",
    "fig, ax = plt.subplots()\n",
    "grouped = df.groupby('label')\n",
    "for key, group in grouped:\n",
    "    group.plot(ax=ax, kind='scatter', x='x', y='y', label=key, color=colors[key])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b0d432",
   "metadata": {},
   "source": [
    "You can see that this will be a tricky example for any linear classifier. There's no way of drawing a line through this space to separate the two classes. A SVM might work well and, as we will see in this example, a neural network handles it well too.\n",
    "\n",
    "Let's split our data as usual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bfb61fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f415d446",
   "metadata": {},
   "source": [
    "### 2.2 Neural Network with linear Kernel\n",
    "\n",
    "Now, we create a neural network with two hidden layers (just like before) but now, instead of just using a sigmoid layer at the very end, we are adding linear layers to the network. This will help us understand how well a binary classifier would work for the data earlier.\n",
    "\n",
    "The other thing I would like you to try here is to run multiple epochs. One epoch refers to one complete run of the whole training dataset through the network. You'll remember that we're running through forward once and then backward once to update our weights and biases (backpropagation). When we've completed that cycle, we've run one epoch. Running multiple epochs (by then pushing the same data through again) can improve the performance of your network, so it's common to run at least a few. You can specify this in the model.fit() function.\n",
    "\n",
    "**TASK**\n",
    "- Build a neural network with two hidden layers like in Section 1\n",
    "- But: Use a linear activation function in each hidden layer\n",
    "- Use a sigmoid activation function in the last layer to get a probability outcome for binary classification\n",
    "- Run the model for 100 epochs\n",
    "- Calculate accuracy/AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "57037c51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_3 (Dense)             (None, 50)                150       \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 50)                2550      \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 51        \n",
      "                                                                 \n",
      " activation (Activation)     (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2751 (10.75 KB)\n",
      "Trainable params: 2751 (10.75 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6951 - accuracy: 0.5043\n",
      "Epoch 2/100\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.6944 - accuracy: 0.5014\n",
      "Epoch 3/100\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6939 - accuracy: 0.5143\n",
      "Epoch 4/100\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.6935 - accuracy: 0.5071\n",
      "Epoch 5/100\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.6933 - accuracy: 0.5200\n",
      "Epoch 6/100\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6932 - accuracy: 0.5157\n",
      "Epoch 7/100\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.6930 - accuracy: 0.5143\n",
      "Epoch 8/100\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6929 - accuracy: 0.5157\n",
      "Epoch 9/100\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.6929 - accuracy: 0.5114\n",
      "Epoch 10/100\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.6927 - accuracy: 0.5129\n",
      "Epoch 11/100\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.6928 - accuracy: 0.5071\n",
      "Epoch 12/100\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.6926 - accuracy: 0.5114\n",
      "Epoch 13/100\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6926 - accuracy: 0.5100\n",
      "Epoch 14/100\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.6925 - accuracy: 0.5171\n",
      "Epoch 15/100\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6925 - accuracy: 0.5186\n",
      "Epoch 16/100\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.6926 - accuracy: 0.5214\n",
      "Epoch 17/100\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.6924 - accuracy: 0.5157\n",
      "Epoch 18/100\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6925 - accuracy: 0.5243\n",
      "Epoch 19/100\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.6926 - accuracy: 0.5243\n",
      "Epoch 20/100\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6925 - accuracy: 0.5214\n",
      "Epoch 21/100\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.6925 - accuracy: 0.5214\n",
      "Epoch 22/100\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.6925 - accuracy: 0.5243\n",
      "Epoch 23/100\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.6925 - accuracy: 0.5200\n",
      "Epoch 24/100\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.6926 - accuracy: 0.5257\n",
      "Epoch 25/100\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6925 - accuracy: 0.5229\n",
      "Epoch 26/100\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.6925 - accuracy: 0.5286\n",
      "Epoch 27/100\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6925 - accuracy: 0.5243\n",
      "Epoch 28/100\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.6925 - accuracy: 0.5243\n",
      "Epoch 29/100\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.6924 - accuracy: 0.5171\n",
      "Epoch 30/100\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6925 - accuracy: 0.5257\n",
      "Epoch 31/100\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.6925 - accuracy: 0.5286\n",
      "Epoch 32/100\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6925 - accuracy: 0.5157\n",
      "Epoch 33/100\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.6925 - accuracy: 0.5229\n",
      "Epoch 34/100\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.6925 - accuracy: 0.5214\n",
      "Epoch 35/100\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6924 - accuracy: 0.5300\n",
      "Epoch 36/100\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.6924 - accuracy: 0.5257\n",
      "Epoch 37/100\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6925 - accuracy: 0.5243\n",
      "Epoch 38/100\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.6925 - accuracy: 0.5300\n",
      "Epoch 39/100\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.6925 - accuracy: 0.5329\n",
      "Epoch 40/100\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6926 - accuracy: 0.5243\n",
      "Epoch 41/100\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.6925 - accuracy: 0.5157\n",
      "Epoch 42/100\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.6925 - accuracy: 0.5229\n",
      "Epoch 43/100\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6926 - accuracy: 0.5257\n",
      "Epoch 44/100\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.6925 - accuracy: 0.5243\n",
      "Epoch 45/100\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6925 - accuracy: 0.5314\n",
      "Epoch 46/100\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.6924 - accuracy: 0.5286\n",
      "Epoch 47/100\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6925 - accuracy: 0.5300\n",
      "Epoch 48/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 0.6926 - accuracy: 0.5271\n",
      "Epoch 49/100\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6924 - accuracy: 0.5286\n",
      "Epoch 50/100\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6926 - accuracy: 0.5343\n",
      "Epoch 51/100\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.6925 - accuracy: 0.5229\n",
      "Epoch 52/100\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.6925 - accuracy: 0.5271\n",
      "Epoch 53/100\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.6924 - accuracy: 0.5329\n",
      "Epoch 54/100\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.6924 - accuracy: 0.5300\n",
      "Epoch 55/100\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6925 - accuracy: 0.5200\n",
      "Epoch 56/100\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.6925 - accuracy: 0.5243\n",
      "Epoch 57/100\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6923 - accuracy: 0.5257\n",
      "Epoch 58/100\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.6926 - accuracy: 0.5157\n",
      "Epoch 59/100\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.6926 - accuracy: 0.5257\n",
      "Epoch 60/100\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.6924 - accuracy: 0.5286\n",
      "Epoch 61/100\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.6924 - accuracy: 0.5257\n",
      "Epoch 62/100\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6923 - accuracy: 0.5314\n",
      "Epoch 63/100\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.6925 - accuracy: 0.5271\n",
      "Epoch 64/100\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6924 - accuracy: 0.5300\n",
      "Epoch 65/100\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.6925 - accuracy: 0.5286\n",
      "Epoch 66/100\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.6926 - accuracy: 0.5186\n",
      "Epoch 67/100\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6924 - accuracy: 0.5300\n",
      "Epoch 68/100\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.6925 - accuracy: 0.5257\n",
      "Epoch 69/100\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6924 - accuracy: 0.5300\n",
      "Epoch 70/100\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.6926 - accuracy: 0.5286\n",
      "Epoch 71/100\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6924 - accuracy: 0.5214\n",
      "Epoch 72/100\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.6925 - accuracy: 0.5343\n",
      "Epoch 73/100\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.6925 - accuracy: 0.5157\n",
      "Epoch 74/100\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6925 - accuracy: 0.5229\n",
      "Epoch 75/100\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.6924 - accuracy: 0.5329\n",
      "Epoch 76/100\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6925 - accuracy: 0.5357\n",
      "Epoch 77/100\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.6925 - accuracy: 0.5243\n",
      "Epoch 78/100\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.6924 - accuracy: 0.5200\n",
      "Epoch 79/100\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6925 - accuracy: 0.5271\n",
      "Epoch 80/100\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.6924 - accuracy: 0.5257\n",
      "Epoch 81/100\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6925 - accuracy: 0.5271\n",
      "Epoch 82/100\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.6924 - accuracy: 0.5314\n",
      "Epoch 83/100\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6925 - accuracy: 0.5200\n",
      "Epoch 84/100\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.6925 - accuracy: 0.5214\n",
      "Epoch 85/100\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.6924 - accuracy: 0.5343\n",
      "Epoch 86/100\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6923 - accuracy: 0.5314\n",
      "Epoch 87/100\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.6925 - accuracy: 0.5300\n",
      "Epoch 88/100\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6924 - accuracy: 0.5243\n",
      "Epoch 89/100\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.6925 - accuracy: 0.5271\n",
      "Epoch 90/100\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.6924 - accuracy: 0.5300\n",
      "Epoch 91/100\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6924 - accuracy: 0.5286\n",
      "Epoch 92/100\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.6925 - accuracy: 0.5214\n",
      "Epoch 93/100\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 0.6924 - accuracy: 0.5300\n",
      "Epoch 94/100\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.6925 - accuracy: 0.5300\n",
      "Epoch 95/100\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.6924 - accuracy: 0.5329\n",
      "Epoch 96/100\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6925 - accuracy: 0.5314\n",
      "Epoch 97/100\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.6926 - accuracy: 0.5229\n",
      "Epoch 98/100\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 0.6925 - accuracy: 0.5243\n",
      "Epoch 99/100\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.6925 - accuracy: 0.5300\n",
      "Epoch 100/100\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 0.6925 - accuracy: 0.5271\n",
      "10/10 [==============================] - 0s 881us/step\n",
      "Accuracy: 0.45666666666666667\n",
      "AUC: 0.4483754833548158\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "\n",
    "# As before, specify the size of our input and output.\n",
    "input_dim = X_train.shape[1]\n",
    "output_dim = 1\n",
    "\n",
    "# We're building a sequential model again.\n",
    "model = Sequential()\n",
    "\n",
    "# Add the input layer and connect to 50 hidden neurons\n",
    "model.add(Dense(50,input_dim=input_dim, activation='linear'))\n",
    "\n",
    "# See the activation type of the layer. Before, we only added this layer as a very last layer to change\n",
    "# our output, but here we can transform the data while feeding it through the layers.\n",
    "\n",
    "# Extra hidden layer \n",
    "model.add(Dense(50, activation='linear'))\n",
    "#model.add(Activation('linear'))\n",
    "\n",
    "# Connect the previous layer to the output layer\n",
    "model.add(Dense(output_dim))\n",
    "\n",
    "# Add a final layer for classification based on the sigmoid function. This will allows us the binary\n",
    "# classification into 1/0 that we're looking for.\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "# We use a different optimiser here instead of stochastic gradient descent\n",
    "# This is not important now, but it shows you that options exist for different scenarios.\n",
    "model.compile(optimizer='sgd',loss='binary_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "# Fit to training data, test on test data and print a summary output.\n",
    "model.summary()\n",
    "model.fit(X_train,y_train,epochs=100)\n",
    "prediction_prob = model.predict(X_test)\n",
    "prediction_class = (prediction_prob > 0.5).astype(\"int32\")\n",
    "\n",
    "print('Accuracy:', accuracy_score(y_test,prediction_class))\n",
    "print('AUC:',roc_auc_score(y_test,prediction_prob))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2587109b",
   "metadata": {},
   "source": [
    "You will hopefully notice that your model does not perform well. This is to be expected: We are de facto trying to fit a linear classifier to the data, which we could clearly see in our plot is not linearly dividable. \n",
    "\n",
    "So, let's try this again. But this time, we will use a different kernel.\n",
    "\n",
    "### 2.3 Neural network with ReLu activation function\n",
    "\n",
    "There's a lot of different activation function to choose from. You can find them in the Keras documentation [here](https://keras.io/api/layers/activations/). We've already seen sigmoid and linear in action. This time, we will use a ReLU function in the hidden layers and a sigmoid function in the output layer.\n",
    "\n",
    "**TASK**\n",
    "\n",
    "Repeat the model from 2.2, but change the activation functions:\n",
    "- ReLU function in hidden layers\n",
    "- sigmoid function in output layer\n",
    "\n",
    "Compare the model performance to the model in 2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ac3fe95d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/keras/src/layers/core/dense.py:85: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,550</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">51</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)             │           \u001b[38;5;34m150\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)             │         \u001b[38;5;34m2,550\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m51\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,751</span> (10.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,751\u001b[0m (10.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,751</span> (10.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,751\u001b[0m (10.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4986 - loss: 0.6935  \n",
      "Epoch 2/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5143 - loss: 0.6921 \n",
      "Epoch 3/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5022 - loss: 0.6928 \n",
      "Epoch 4/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5257 - loss: 0.6906 \n",
      "Epoch 5/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5037 - loss: 0.6918 \n",
      "Epoch 6/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4895 - loss: 0.6934 \n",
      "Epoch 7/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5283 - loss: 0.6889 \n",
      "Epoch 8/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5264 - loss: 0.6896 \n",
      "Epoch 9/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5254 - loss: 0.6901 \n",
      "Epoch 10/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5003 - loss: 0.6912 \n",
      "Epoch 11/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5504 - loss: 0.6872 \n",
      "Epoch 12/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5343 - loss: 0.6883 \n",
      "Epoch 13/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5141 - loss: 0.6893 \n",
      "Epoch 14/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5485 - loss: 0.6871 \n",
      "Epoch 15/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5199 - loss: 0.6894\n",
      "Epoch 16/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5419 - loss: 0.6884 \n",
      "Epoch 17/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5266 - loss: 0.6897 \n",
      "Epoch 18/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5430 - loss: 0.6869 \n",
      "Epoch 19/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5388 - loss: 0.6871 \n",
      "Epoch 20/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5441 - loss: 0.6872 \n",
      "Epoch 21/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5728 - loss: 0.6854 \n",
      "Epoch 22/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5550 - loss: 0.6861 \n",
      "Epoch 23/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5538 - loss: 0.6861 \n",
      "Epoch 24/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5546 - loss: 0.6854 \n",
      "Epoch 25/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5555 - loss: 0.6846 \n",
      "Epoch 26/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5633 - loss: 0.6851 \n",
      "Epoch 27/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 991us/step - accuracy: 0.5688 - loss: 0.6842\n",
      "Epoch 28/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5621 - loss: 0.6848 \n",
      "Epoch 29/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5761 - loss: 0.6853 \n",
      "Epoch 30/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5729 - loss: 0.6860 \n",
      "Epoch 31/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5929 - loss: 0.6837 \n",
      "Epoch 32/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5629 - loss: 0.6853 \n",
      "Epoch 33/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6164 - loss: 0.6815 \n",
      "Epoch 34/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6219 - loss: 0.6818 \n",
      "Epoch 35/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5932 - loss: 0.6829 \n",
      "Epoch 36/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5743 - loss: 0.6845 \n",
      "Epoch 37/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6077 - loss: 0.6824 \n",
      "Epoch 38/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5867 - loss: 0.6819 \n",
      "Epoch 39/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6069 - loss: 0.6815 \n",
      "Epoch 40/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6117 - loss: 0.6805 \n",
      "Epoch 41/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6455 - loss: 0.6792 \n",
      "Epoch 42/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6364 - loss: 0.6797 \n",
      "Epoch 43/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6293 - loss: 0.6801 \n",
      "Epoch 44/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6266 - loss: 0.6801 \n",
      "Epoch 45/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6107 - loss: 0.6797 \n",
      "Epoch 46/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6299 - loss: 0.6803 \n",
      "Epoch 47/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6303 - loss: 0.6799 \n",
      "Epoch 48/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6591 - loss: 0.6792 \n",
      "Epoch 49/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6269 - loss: 0.6795 \n",
      "Epoch 50/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6630 - loss: 0.6771 \n",
      "Epoch 51/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6578 - loss: 0.6781 \n",
      "Epoch 52/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6637 - loss: 0.6778 \n",
      "Epoch 53/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 977us/step - accuracy: 0.6616 - loss: 0.6769\n",
      "Epoch 54/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6578 - loss: 0.6780 \n",
      "Epoch 55/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6623 - loss: 0.6767 \n",
      "Epoch 56/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6647 - loss: 0.6759 \n",
      "Epoch 57/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6795 - loss: 0.6751 \n",
      "Epoch 58/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7006 - loss: 0.6736 \n",
      "Epoch 59/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7048 - loss: 0.6748 \n",
      "Epoch 60/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6953 - loss: 0.6743 \n",
      "Epoch 61/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 991us/step - accuracy: 0.6928 - loss: 0.6745\n",
      "Epoch 62/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7233 - loss: 0.6730 \n",
      "Epoch 63/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6927 - loss: 0.6742 \n",
      "Epoch 64/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7272 - loss: 0.6718 \n",
      "Epoch 65/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7115 - loss: 0.6726 \n",
      "Epoch 66/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7042 - loss: 0.6729 \n",
      "Epoch 67/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6952 - loss: 0.6723 \n",
      "Epoch 68/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7525 - loss: 0.6704 \n",
      "Epoch 69/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7478 - loss: 0.6706 \n",
      "Epoch 70/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 923us/step - accuracy: 0.7212 - loss: 0.6712\n",
      "Epoch 71/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7448 - loss: 0.6701 \n",
      "Epoch 72/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7382 - loss: 0.6690 \n",
      "Epoch 73/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 929us/step - accuracy: 0.7507 - loss: 0.6696\n",
      "Epoch 74/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7554 - loss: 0.6685 \n",
      "Epoch 75/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7708 - loss: 0.6670\n",
      "Epoch 76/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7863 - loss: 0.6675 \n",
      "Epoch 77/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 959us/step - accuracy: 0.7620 - loss: 0.6667\n",
      "Epoch 78/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7708 - loss: 0.6676 \n",
      "Epoch 79/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8084 - loss: 0.6654 \n",
      "Epoch 80/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 996us/step - accuracy: 0.7936 - loss: 0.6635\n",
      "Epoch 81/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8209 - loss: 0.6649 \n",
      "Epoch 82/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7967 - loss: 0.6634 \n",
      "Epoch 83/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7969 - loss: 0.6648 \n",
      "Epoch 84/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8192 - loss: 0.6633 \n",
      "Epoch 85/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8205 - loss: 0.6632 \n",
      "Epoch 86/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8207 - loss: 0.6621 \n",
      "Epoch 87/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8210 - loss: 0.6635 \n",
      "Epoch 88/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8117 - loss: 0.6608 \n",
      "Epoch 89/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8320 - loss: 0.6612 \n",
      "Epoch 90/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 892us/step - accuracy: 0.8433 - loss: 0.6601\n",
      "Epoch 91/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8445 - loss: 0.6600 \n",
      "Epoch 92/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8551 - loss: 0.6581 \n",
      "Epoch 93/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8440 - loss: 0.6592 \n",
      "Epoch 94/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8413 - loss: 0.6594 \n",
      "Epoch 95/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 998us/step - accuracy: 0.8500 - loss: 0.6558\n",
      "Epoch 96/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8559 - loss: 0.6552 \n",
      "Epoch 97/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8438 - loss: 0.6557 \n",
      "Epoch 98/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8743 - loss: 0.6561 \n",
      "Epoch 99/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8735 - loss: 0.6542 \n",
      "Epoch 100/100\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8576 - loss: 0.6573 \n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "Accuracy: 0.8433333333333334\n",
      "AUC: 0.971194879089616\n"
     ]
    }
   ],
   "source": [
    "input_dim = X_train.shape[1]\n",
    "output_dim = 1\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(50,input_dim=input_dim, activation='relu'))\n",
    "\n",
    "model.add(Dense(50, activation='relu'))\n",
    "\n",
    "model.add(Dense(output_dim, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='sgd',loss='binary_crossentropy',metrics=['accuracy'])\n",
    "model.summary()\n",
    "model.fit(X_train,y_train,epochs=100)\n",
    "prediction_prob = model.predict(X_test)\n",
    "prediction_class = (prediction_prob > 0.5).astype(\"int32\")\n",
    "\n",
    "print('Accuracy:', accuracy_score(y_test,prediction_class))\n",
    "print('AUC:',roc_auc_score(y_test,prediction_prob))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5eecd73",
   "metadata": {},
   "source": [
    "What do you find? You might notice that your ReLU Kernel is doing marginally better than the linear one. Mine does reasonably well (accuracy around 80%) as long as I run the model multiple epochs (around 100). You can experiment with the impact that activation function and number of epochs has on your model performancae."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e14e32f5",
   "metadata": {},
   "source": [
    "# Section 3: Building neural networks for regression\n",
    "\n",
    "So far we have focused on classification into two classes with neural networks. Now, we will look at the use of neural networks for regression problems. We're going back to our diabetes progression dataset that we've seen in our regression tree building. \n",
    "\n",
    "We will also talk about learning rate - one of the parameters that you can choose in building your network. The learning rate refers to how strongly the model is changed during each of the weights/biases update step of backpropagation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "43f63492",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "dataset = load_diabetes()\n",
    "\n",
    "X = pd.DataFrame(data=dataset['data'],columns=dataset['feature_names'])\n",
    "\n",
    "y = pd.DataFrame(data=dataset['target'],columns=['progression'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f0bd6f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/base.py:432: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3)\n",
    "\n",
    "# Scale the training and the test data\n",
    "X_train = StandardScaler().fit_transform(X_train)\n",
    "X_test = StandardScaler().fit(X_train).transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e7ad91",
   "metadata": {},
   "source": [
    "The main difference in building a regression neural network versus a classification one is 1) how we choose the activation functions and 2) how we choose the loss function.\n",
    "\n",
    "Regarding 1), we don't need the sigmoid function for the binary classification anymore. And regarding 2) remember that in Section 2 we used binary_crossentropy for loss. This time we obtain a metric that can be used for regression, the mean squared error, instead. We also use this as a metric for reporting, instead of accuracy. You can calculate it using the mean_squared_error function in sklearn.metrics, as we've done before.\n",
    "\n",
    "Just to learn something new we now also use a different optimiser (instead of stochastic gradient descent) which works better in this instance and run just 10 epochs to save computing time. You can read more about different optimizers [here](https://keras.io/api/optimizers/) if you're curious.\n",
    "\n",
    "**TASK**\n",
    "\n",
    "- Build a neural network with one hidden layer to predict y\n",
    "- Choose mean squared error for the loss function and performance outcome\n",
    "- Use 'adam' as the optimizer for the model instead of 'sgd'\n",
    "- Run the model for 10 epochs\n",
    "\n",
    "Note that our `output_dim = 1` as we are predicting a single real number per observation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4cd19f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import layers\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1bdaa58a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 50)                550       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 601 (2.35 KB)\n",
      "Trainable params: 601 (2.35 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "10/10 [==============================] - 1s 2ms/step - loss: 29943.2773 - mean_squared_error: 29943.2773\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 29883.1270 - mean_squared_error: 29883.1270\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 29816.4395 - mean_squared_error: 29816.4395\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 0s 4ms/step - loss: 29755.7441 - mean_squared_error: 29755.7441\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 29686.2500 - mean_squared_error: 29686.2500\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 29617.2324 - mean_squared_error: 29617.2324\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 29537.4668 - mean_squared_error: 29537.4668\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 29449.4961 - mean_squared_error: 29449.4961\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 29352.3301 - mean_squared_error: 29352.3301\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 29252.4961 - mean_squared_error: 29252.4961\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "RMSE: 162.98973371579478\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error as mse\n",
    "\n",
    "input_dim = X_train.shape[1]\n",
    "# We only have 1 output dimension, as our regression outputs a real number\n",
    "output_dim = 1\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(50,input_dim=input_dim))\n",
    "\n",
    "model.add(Dense(output_dim))\n",
    "\n",
    "# We now use a dedicated optimizer instance - this allows us to input the learning rate later\n",
    "model.compile(optimizer='adam',loss='mean_squared_error',metrics=['mean_squared_error'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# We add the number of epochs as a parameter to our fit method\n",
    "model.fit(X_train,y_train,epochs=10)\n",
    "\n",
    "prediction = model.predict(X_test)\n",
    "\n",
    "print('RMSE:', np.sqrt(mse(y_test,prediction)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad754f3f",
   "metadata": {},
   "source": [
    "Take a look at the output of the model and how it shows for each epoch how the mean squared error is decreasing. You can watch how the model is learning each round it runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89370e47",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
